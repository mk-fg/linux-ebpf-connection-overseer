#!/usr/bin/env python

# Relevant docs:
#  https://docs.ebpf.io/ebpf-library/libbpf/userspace/
#  https://libbpf.readthedocs.io/en/latest/api.html

import collections as cs, ipaddress as ip, pathlib as pl
import ctypes as ct, socket as so, functools as ft
import os, sys, re, struct, errno, time, json, pwd, signal, select


class adict(dict):
	def __init__(self, *args, **kws):
		super().__init__(*args, **kws)
		self.__dict__ = self

def sz_repr(sz, _units=list(reversed(
		list((u, 2 ** (i * 10)) for i, u in enumerate('BKMGT')) ))):
	for u, u1 in _units:
		if sz > u1: break
	return f'{sz / u1:.1f}'.removesuffix('.0') + u

def openat2(p, mode='r', _cache=[]):
	'More flexible open() that avoids symlink-related race-conditions'
	# Also allows to open for writing without O_CREAT.
	# Way to validate opened path without disallowing symlinks entirely:
	#  p = realpath(path); validate_is_acceptable(p); file = openat2(p, no_symlinks)
	# As of 2022-10-13 glibc has no openat2() wrapper yet, hence syscall here.
	if not _cache:
		def _openat2(p, flags, _syscall=ct.CDLL(None, use_errno=True).syscall):
			args = ct.create_string_buffer(struct.pack(
				'@QQQ', flags | os.O_NOFOLLOW, 0, res_no_symlinks := 0x04 ))
			fd = _syscall(437, -100, str(p).encode(), args, 24)
			if fd < 0: raise OSError(err := ct.get_errno(), os.strerror(err))
			return fd
		_cache.append(_openat2)
	flags = 0
	if 'r' in mode: flags |= os.O_RDONLY
	if 'w' in mode: assert not flags; flags |= os.O_WRONLY
	if '+' in mode: assert not flags; flags |= os.O_RDWR
	if 'c' in mode: flags |= os.O_CREAT
	if 'x' in mode: flags |= os.O_EXCL
	if 't' in mode: flags |= os.O_TRUNC
	if 'a' in mode: flags |= os.O_APPEND
	mode = mode.translate(dict.fromkeys(ord(c) for c in 'ct'))
	return open(_cache[0](p, flags | os.O_CLOEXEC), mode)

class TimedCacheDict(cs.UserDict):
	'dict that has values expire and get removed on timeout'
	__slots__, _no_value = ('data', 'ts', 'ts_min', 'timeout', 'bump_on_get'), object()
	timeout_cleanup_slack = 1.5 # oldest-timeout multiplier to cache cleanup
	def __init__(self, timeout, bump_on_get=True):
		self.ts, self.ts_min = dict(), None
		self.timeout, self.bump_on_get = timeout, bump_on_get
		super().__init__()
	def cache(self, k, v=_no_value):
		ts, get_op = time.monotonic(), v is self._no_value
		if get_op and (ts - self.ts.get(k, 0)) > self.timeout: raise KeyError(k)
		if not get_op or self.bump_on_get: self.ts[k] = ts
		v = super().__getitem__(k) if get_op else super().__setitem__(k, v)
		if not self.ts_min: self.ts_min = ts; return v
		elif get_op or ts - self.ts_min <= self.timeout * self.timeout_cleanup_slack: return v
		for k, ts0 in sorted(self.ts.items(), key=lambda kv: kv[1]):
			if ts - ts0 > self.timeout: self.pop(k, None); del self.ts[k]; continue
			self.ts_min = ts0; break
		else: self.ts_min = None
		return v
	def __iter__(self):
		for k in self.data:
			if k in self: yield k
	def __contains__(self, k):
		return k in self.data and (time.monotonic() - self.ts.get(k, 0)) <= self.timeout
	def __getitem__(self, k): return self.cache(k)
	def __setitem__(self, k, v): return self.cache(k, v)

p = lambda *a,**kw: print(*a, **kw, flush=True)
p_err = lambda *a,**kw: print(*a, **kw, file=sys.stderr, flush=True) or 1
err_fmt = lambda err: f'[{err.__class__.__name__}] {err}'


class BPFError(Exception): pass

class BPFMap:

	class _rb_struct(ct.Structure): pass
	class _map_info(ct.Structure): _align_, _fields_ = 8, list( (k, ct.c_uint)
		for k in 'type id key value entires flags'.split() ) + [('name', ct.c_char * 16)]
	class _map_batch_opts(ct.Structure): _fields_ = [
		('sz', ct.c_size_t), ('elem_flags', ct.c_ulonglong), ('flags', ct.c_ulonglong) ]
	_rb_handler_t = ct.CFUNCTYPE(ct.c_int, ct.c_void_p, ct.c_void_p, ct.c_size_t)

	_libbpf = None # needed for ringbuf_process_ring asm to process data
	@classmethod
	def libbpf_init(cls):
		if BPFMap._libbpf: return
		lib = BPFMap._libbpf = ct.CDLL('libbpf.so.1', use_errno=True)
		ptr, cint, cuint, cvoid = ct.POINTER, ct.c_int, ct.c_uint, ct.c_void_p
		lib.ring_buffer__new.argtypes = cint, cls._rb_handler_t, cvoid, cvoid
		lib.ring_buffer__new.restype = ptr(cls._rb_struct)
		lib.ring_buffer__poll.argtypes = ptr(cls._rb_struct), cint
		lib.bpf_map_get_info_by_fd.argtypes = cint, ptr(cls._map_info), ptr(cuint)
		lib.bpf_map_lookup_batch.argtypes = ( cint,
			cvoid, cvoid, cvoid, cvoid, ptr(cuint), ptr(cls._map_batch_opts) )

	fd = fd_close = None
	def map_fd(self, fd=None, path=None):
		if self.fd is not None: return self.fd
		if fd is None:
			if not path: raise ValueError('Either bpf-map fd or path must be specified')
			if (fd := self._libbpf.bpf_obj_get(str(path).encode())) < 0:
				raise BPFError(f'Failed bpf-map init from path for [ {path} ]')
			self.fd_close = True
		self.fd = fd; return fd

	def __enter__(self): return self
	def __exit__(self, *err): self.close()
	def close(self):
		if self.fd_close and self.fd is not None: os.close(self.fd); self.fd = None

	def ev_parse( self, ev, o=0,
			_st=struct.Struct('<BQ16s16sHHII16sQQQ'), _ct_proto='tcp udp x'.split(),
			_fields='ct ns laddr raddr lport rport pid uid comm ns_trx rx tx'.split(),
			_ct_af=((so.AddressFamily.AF_INET6, 16), (so.AddressFamily.AF_INET, 4)) ):
		e = adict(zip(_fields, _st.unpack_from(ev, offset=o)))
		if not e.ct: return
		e.proto, (e.af, n) = _ct_proto[(e.ct-1)//2], _ct_af[e.ct%2]
		for k in 'laddr', 'raddr': e[k] = ip.ip_address(e[k][:n])
		e.comm = e.comm.rstrip(b'\0').decode()
		return e

class BPFMapU64HashTable(BPFMap):
	# There's no good high-level API for opening maps from fds,
	#   so using "low-level" api here, which is same thing but with less hassle.
	# Also trivial to use direct syscalls instead, but libbpf is needed for rbs anyway.

	def __init__(self, fd=None, path=None):
		self.libbpf_init()
		self.fd, info_fn = self.map_fd(fd, path), self._libbpf.bpf_map_get_info_by_fd
		info, n = self._map_info(), ct.c_uint(n0 := ct.sizeof(self._map_info))
		if info_fn(self.fd, ct.byref(info), ct.byref(n)) or n.value < n0 or info.key != 8:
			raise BPFError(f'libbpf bpf_map_get_info failed [fd={fd} path={path}]')
		self.name, self.vsz, self.n = info.name.decode(), info.value, info.entires
		self.batch_flags = self._map_batch_opts(sz=ct.sizeof(self._map_batch_opts))

	def read(self, batch=64):
		# Array batches always iterate over all entries, with all keys
		#  always set sequentially, but values are zeroed-out for unused elements.
		# ENOENT shouldn't happen here, but indicates that q goes beyond max_entries.
		vals, a, b = list(), ct.pointer(ct.c_void_p()), ct.pointer(ct.c_void_p())
		q, vb_data = ct.c_uint(), bytearray((vsz := self.vsz) * batch)
		kb, vb = (ct.c_ulonglong*batch)(), ct.c_char.from_buffer(vb_data)
		kb_p, vb_p, q_p = (ct.pointer(v) for v in [kb, vb, q])
		while c := self.n - len(vals):
			c = q.value = min(batch, c)
			if err := self._libbpf.bpf_map_lookup_batch( self.fd,
					None if not vals else a, b, kb_p, vb_p, q_p, self.batch_flags ):
				if -err != errno.ENOENT: raise BPFError('bpf_map_lookup_batch failed')
			for n in range(q.value):
				if not (ev := self.ev_parse(vb_data, n*vsz)): return vals
				vals.append(ev)
			if err or q.value < c: break
			a, b = b, a
		return vals

class BPFMapRingBuffer(BPFMap):

	def __init__(self, fd=None, path=None):
		self.libbpf_init()
		self.updates, self.handler = list(), self._rb_handler_t(self._ev_handler)
		self.rb = self._libbpf.ring_buffer__new(self.map_fd(fd, path), self.handler, None, None)
		if not self.rb: raise BPFError(f'libbpf ring_buffer__new failed [fd={fd} path={path}]')

	def _ev_handler(self, ctx, ev, n):
		return self.updates.append(self.ev_parse(
			bytes((ct.c_char*n).from_address(ev)) )) or 0

	def close(self):
		if self.rb: self._libbpf.ring_buffer__free(self.rb); self.rb = None
		super().close()

	def wait(self, timeout=1.0):
		self.updates.clear()
		if self._libbpf.ring_buffer__poll(
			self.rb, int(timeout*1000) ) <= 0: return () # timeout/error
		return tuple(self.updates)


def ev_conv(e, cache=None, all_data=False):
	# XXX: add aliases, resolve addrs to hosts/asns
	ev = adict(ns=e.ns, ns_trx=e.ns_trx)
	if not (cache and (u := cache.get(e.uid))):
		try: u = pwd.getpwuid(e.uid).pw_name
		except KeyError: u = str(e.uid)
		if cache is not None: cache[e.uid] = u
	ev.line = ' :: '.join([ # XXX: "comm [cgroup]" instead of just comm
		time.strftime('%H:%M', time.localtime(e.ns / 1e9)),
		u, re.sub(r'::+', ':', e.comm),
		f'{e.raddr} {e.rport}' + (f'/{e.proto}' if e.proto != 'tcp' else ''),
		f'v {sz_repr(e.rx)} / {sz_repr(e.tx)} ^' ])
	if all_data: ev = dict(e, **ev)
	return ev

def json_conv(v):
	if ip_repr := getattr(v, 'compressed', None): return ip_repr
	raise TypeError(f'Non-JSON type [{v.__class__.__name__}] {v}')

def stream_events(cache, rb, dst, ev_proc, replay_limit=None):
	def _dst_write(ev, ns):
		try:
			dst.write(json.dumps(ev, default=json_conv))
			dst.write('\n'); dst.flush()
		except BrokenPipeError: # pipe closed
			if dst is sys.stdout: os.dup2(os.open(
				os.devnull, os.O_WRONLY ), dst.fileno())
			return True
	with select.epoll(sizehint=2) as poll:
		ns_cache, ns_cutoff, ns = 0, 0, time.monotonic_ns()
		if replay_limit: ns_cutoff = ns - replay_limit * 1_000_000_000
		for ev in sorted(cache.read(), key=lambda ev: ev.ns_trx):
			if (ns_cache := ev.ns_trx) < ns_cutoff: continue
			if _dst_write(ev_proc(ev), ns): return
		if not rb: return # one-off cache dump
		poll.register(dst_fd := dst.fileno(), 0)
		poll.register(rb.fd, select.EPOLLIN)
		while True:
			if not (ev_fds := poll.poll(maxevents=1)): continue
			if ev_fds[0][0] == dst_fd: break # dst pipe closed
			for ev in rb.wait(0.1): # shouldn't actually need to wait
				if ev.ns_trx <= ns_cache or ev.ns_trx < ns_cutoff: continue
				if _dst_write(ev_proc(ev), time.monotonic_ns()): return
			if not ev_fds[0][1] & select.EPOLLIN: break # rb fd closed

def main(argv=None):
	import argparse, textwrap
	dd = lambda text: re.sub( r' \t+', ' ',
		textwrap.dedent(text).strip('\n') + '\n' ).replace('\t', '  ')
	parser = argparse.ArgumentParser(
		formatter_class=argparse.RawTextHelpFormatter, description=dd('''
			Script to monitor and forward eBPF events to UI components as json-lines.
			By default checks systemd service env vars,
				uses map sockets from there and outputs stream of events to stdout.
			Alternative is to use -p/--pin option to open/use bpffs-pinned maps.
			Streams events from pre-populated conn_map first and updates after that.
			Replayed old event times are calculated using monotonic clock offset
				from current wall-clock time, so don't take system suspend into account.'''))
	parser.add_argument('-f', '--fifo', metavar='path', help=dd('''
		FIFO path to use to output stream of events instead of stdout.
		Must be pre-existing, will be reused when other side closes it,
			always sending all stored connection table events after re-opening.'''))
	parser.add_argument('-p', '--pin', metavar='path', help=dd('''
		Top-level path under which all eBPF objects are pinned.
		This script will only access objects under "map" subdirectory.
		Typically under /sys/fs/bpf/ mountpoint. Might require privileged access.'''))
	parser.add_argument('-r', '--replay-window', type=float, metavar='seconds',
		help='Ignore pre-buffered events older than specified number of seconds.')
	parser.add_argument('--extra-ev-data', action='store_true',
		help='Pass through all extra event info for debugging, not just the necessary stuff.')
	parser.add_argument('--dump-cache', action='store_true',
		help='Only stream/dump data for conn_map cache and exit.')
	opts = parser.parse_args(sys.argv[1:] if argv is None else argv)

	if not opts.pin:
		sd_pid, sd_fds = (
			os.environ.get(f'LISTEN_{k}', '') for k in 'PID FDNAMES'.split() )
		if not sd_pid.isdigit() or int(sd_pid) != os.getpid():
			parser.error('systemd env LISTEN_PID does not match this process')
		sd_fds = (
			adict((k[:-4], 3+n) for n, k in enumerate(sd_fds.split(':')) if k.endswith('__v1'))
			if all(re.search(r'__v\d$', k) for k in sd_fds.split(':')) # versioned fds
			else adict((k, 3 + n) for n, k in enumerate(sd_fds.split(':'))) )
		bpf_rb = BPFMapRingBuffer(sd_fds.updates)
		bpf_cache = BPFMapU64HashTable(sd_fds.conn_map)
		if sd_sock := os.environ.get('NOTIFY_SOCKET'):
			if sd_sock[0] not in ('/', '@'): parser.error('Unsupported sd_notify socket')
			if sd_sock[0] == '@': sd_sock = '\0' + sd_sock[1:]
			with so.socket(so.AF_UNIX, so.SOCK_DGRAM | so.SOCK_CLOEXEC) as s:
				s.connect(sd_sock); s.sendall(b'READY=1')

	else:
		p_maps = pl.Path(opts.pin) / 'maps'
		bpf_rb = BPFMapRingBuffer(path=p_maps / 'updates')
		bpf_cache = BPFMapU64HashTable(path=p_maps / 'conn_map')

	signal.signal(signal.SIGINT, signal.SIG_DFL)
	with bpf_rb as rb, bpf_cache as cache:
		if opts.dump_cache: rb = None
		stream_kws = dict( cache=cache, rb=rb, replay_limit=opts.replay_window,
			ev_proc=ft.partial(ev_conv, cache=TimedCacheDict(5*60), all_data=opts.extra_ev_data) )
		if not opts.fifo: return stream_events(dst=sys.stdout, **stream_kws)
		# XXX: support sending to multiple receivers
		while dst := openat2(opts.fifo, 'w'):
			try: stream_events(dst=dst, **stream_kws)
			finally:
				try: dst.close()
				except BrokenPipeError: pass

if __name__ == '__main__': sys.exit(main())
